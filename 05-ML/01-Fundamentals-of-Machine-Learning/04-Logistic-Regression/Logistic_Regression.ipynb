{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Up until now, you have been modeling a regression task. This time, you are going to be modeling a classification task, on the famous Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Load the `titanic.csv` dataset into this notebook as a pandas dataframe, and display its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Titanic_dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Variable    Definition      Key\n",
    "\n",
    "survival    Survival        0 = No, 1 = Yes\n",
    "pclass      Ticket class    1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex         Sex\n",
    "Age         Age in years\n",
    "sibsp       # of siblings / spouses aboard the Titanic\n",
    "parch       # of parents / children aboard the Titanic\n",
    "ticket      Ticket number\n",
    "fare        Passenger fare\n",
    "cabin       Cabin number\n",
    "embarked    Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá We want to predict whether a passenger survived (`Survived`) the Titanic disaster, according to the following features:\n",
    "\n",
    "- The class in which she/he was travelling (`Pclass`)\n",
    "- The number of siblings/spouses he had onboard (`SibSp`)\n",
    "- The number of parents/children he had onboard (`Parch`)\n",
    "- The fare he paid for the ticket (`Fare`)\n",
    "\n",
    "‚ùìHow accurate would a `LogisticRegression` model be at such a task? Save the accuracy under variable name `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('accuracy',\n",
    "                         accuracy = accuracy\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. In-depth diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìWe've evaluated the accuracy of the model at predicting, but we want to investigate its performance in more depth. Is the model overfitting? Underfitting? How many learning examples does it need to learn optimally on the given features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary> ‚ÑπÔ∏è Once you have completed your diagnosis, unfold this cell </summary>   \n",
    "    \n",
    "<br/>\n",
    "You should have plotted the learning curves.\n",
    "\n",
    "üëâ The curves should have converged:\n",
    "- The model is not overfitting (no variance): it generalizes well.\n",
    "\n",
    "üëâ The test score stops increasing around 500 training observations:\n",
    "- The model does not need more than 500 training observations to perform optimally on the given features.\n",
    "    \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reduced training size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Evaluate a model on the training size suggested by the curves. Are you able to maintain a similar accuracy? Save the new accuracy under variable name `reduced_training_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è The accuracy should be nearly the same, with a reduced computational expense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('reduced_accuracy',\n",
    "                         accuracy = reduced_training_accuracy\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Did the following person survive the Titanic disaster?\n",
    "\n",
    "- Travelled in class 1 (`Pclass`)\n",
    "- Had no spouse or siblings on board(`SibSp`)\n",
    "- Had no parents or children on board (`Parch`)\n",
    "- Paid 15 for his ticket (`Fare`)\n",
    "\n",
    "‚ö†Ô∏è Make sure the model you use for predicting has the **least computational expense possible**. Save the prediction under variable name `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the probability that the person survived? Compute your answer and save it under variable name `probability`.\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>Hints if you are stuck</summary>\n",
    "\n",
    "Have a look at the method `.predict_proba()`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "challengify"
    ],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('predictions',\n",
    "                         prediction = prediction,\n",
    "                         probability = probability\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Can you trust the predicted probabilities ? (Model Calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ‚ùóÔ∏è Accuracy only evaluate your model performance based on the predicted **classes** 0s and 1s (obtained via`.predict()`)\n",
    "- ‚ùóÔ∏è High accuracy does not necessarily mean that predicted **probabilities** are \"calibrated\" (obtained via `.predict_probas()`)\n",
    "\n",
    "What does \"calibrated\" probabilities mean? \n",
    "> _Among the samples to which your model gave a predict_proba value close to 0.9, approximately 90% actually belong to the positive class._\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/lewagon/data-images/master/math/logistic-regression.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question 1**: Read more about [Calibration](https://scikit-learn.org/stable/modules/calibration.html) on sklearn docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question 2**: Try to implement `CalibrationDisplay` to check if you model is calibrated (on a holdout test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.5)\n",
    "\n",
    "# Fit a model on the train set\n",
    "\n",
    "\n",
    "# Print calibration curve on the test set\n",
    "# $DELETE_BEGIN\n",
    "disp = CalibrationDisplay.from_estimator(model, X_test, y_test, n_bins=7)\n",
    "# $DELETE_ENG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question 3**: Try to calibrate your model using `CalibratedClassifierCV`, and compute your new probability of survival. \n",
    "\n",
    "(Note that logistic regression are already generally well calibrated because they try to minimize the log-loss, refer to lecture https://kitt.lewagon.com/camps/YOUR_CAMP_NUMBER/lectures/content/04-Decision-Science_04-Logistic-Regression.slides.html?title=Logistic-Regression#/2/7/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
