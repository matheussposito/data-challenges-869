{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6068a992",
   "metadata": {},
   "source": [
    "# Natural Language Processing + Decision Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987676fd",
   "metadata": {},
   "source": [
    "ğŸ‘©ğŸ»â€ğŸ« In this challenge, we will combine:\n",
    "* ğŸ—£ Natural Language Processing \n",
    "* ğŸ“Š Decision Science \n",
    "\n",
    "ğŸ¯ The goal is to understand the bad reviews of the products and the sellers on Olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102058e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_columns\",None)\n",
    "\n",
    "# Olist packages\n",
    "from olist.data import Olist\n",
    "from olist.review import Review\n",
    "from olist.order import Order\n",
    "from olist.product_updated import Product\n",
    "from olist.seller_updated import Seller\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Language Processing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "# Vectorizers and NLP Models\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b2062",
   "metadata": {},
   "source": [
    "ğŸ•µğŸ»â€â™‚ï¸ Imagine that the CEO of Olist [Tiago Dalvi](https://www.linkedin.com/in/tiagodalvi/) ask you to read and understand the reviews.\n",
    "\n",
    "- What did customers say about their order if they rated it 1? 2? 3?\n",
    "- What are the most frequent bad reviews about...\n",
    "    - the worst rated products ?\n",
    "    - the wort sellers ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6a699",
   "metadata": {},
   "source": [
    "## (0) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6e3a1",
   "metadata": {},
   "source": [
    "ğŸ‘©ğŸ»â€ğŸ« If you followed the `Decision Science` module, you already have the `olist` package installed and importable. *You can skip this section* and move to the **Data collection** section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db43ed4",
   "metadata": {},
   "source": [
    "### (0.1) Import `olist` package`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a852b",
   "metadata": {},
   "source": [
    "Download a fresh version of the `olist` package:\n",
    "\n",
    "```bash\n",
    "mkdir ~/code/lewagon\n",
    "cd ~/code/lewagon\n",
    "git clone git@github.com:lewagon/olist.git\n",
    "cd olist\n",
    "git fetch\n",
    "git checkout full-package\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e04f7",
   "metadata": {},
   "source": [
    "### (0.2) Download the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e0a457",
   "metadata": {},
   "source": [
    "- Download the datasets from Kaggle https://www.kaggle.com/olistbr/brazilian-ecommerce\n",
    "- Unzip them into the `/data/csv` directory of the `olist` package:\n",
    "\n",
    "```bash\n",
    ".\n",
    "â”œâ”€â”€ README.md\n",
    "â”œâ”€â”€ data\n",
    "â”‚Â Â  â””â”€â”€ csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_customers_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_geolocation_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_order_items_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_order_payments_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_order_reviews_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_orders_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_products_dataset.csv\n",
    "â”‚Â Â      â”œâ”€â”€ olist_sellers_dataset.csv\n",
    "â”‚Â Â      â””â”€â”€ product_category_name_translation.csv\n",
    "â”œâ”€â”€ notebooks\n",
    "â”œâ”€â”€ olist\n",
    "â”‚Â Â  â”œâ”€â”€ README.md\n",
    "â”‚Â Â  â”œâ”€â”€ __init__.py\n",
    "â”‚Â Â  â”œâ”€â”€ data.py\n",
    "â”‚Â Â  â”œâ”€â”€ order.py\n",
    "â”‚Â Â  â”œâ”€â”€ product.py\n",
    "â”‚Â Â  â”œâ”€â”€ product_updated.py\n",
    "â”‚Â Â  â”œâ”€â”€ review.py\n",
    "â”‚Â Â  â”œâ”€â”€ seller.py\n",
    "â”‚Â Â  â”œâ”€â”€ seller_updated.py\n",
    "â”‚Â Â  â””â”€â”€ utils.py\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â””â”€â”€ setup.p\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901b100",
   "metadata": {},
   "source": [
    "### (0.3) Install the `olist` package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88326db7",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "âš ï¸ Restart the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2727e",
   "metadata": {},
   "source": [
    "## (1) Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084d3ea",
   "metadata": {},
   "source": [
    "ğŸ‘‰ The way we designed the `reviews` DataFrame will help us focus on the `product categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6478d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = Review().get_training_data()\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722d282",
   "metadata": {},
   "source": [
    "ğŸ‘‰ We can retrieve the reviews from `order_reviews` within the Olist class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff1a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Olist().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f7168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = data['order_reviews']\n",
    "reviews_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c351b6f",
   "metadata": {},
   "source": [
    "ğŸª¤ We need to collect some information about the orders because:\n",
    "- Back then, customers could review an order even before receiving it\n",
    "- They could also rate an order that they hadn't received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef243692",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = data['orders']\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293d975",
   "metadata": {},
   "source": [
    "ğŸ’¥ Let's merge these three datasets and apply some operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ca7c856",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89666586",
   "metadata": {},
   "source": [
    "ğŸš“ Remove the reviews that were written even before receiving the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddeddb73",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1293c05",
   "metadata": {},
   "source": [
    "ğŸš“ Remove the reviews for undelivered orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fb1b11",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883de25",
   "metadata": {},
   "source": [
    "âœï¸ As some people fill in only the title or the body of a review, it may be a good idea to aggregate them together.\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>ğŸ’¡<i>Hint</i></summary>\n",
    "\n",
    "* Drop rows with either a missing title or a missing comment\n",
    "* Refer to the documentation [pandas.DataFrame.dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) and have a look at the `how` argument..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f34a2dc",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd87ab",
   "metadata": {},
   "source": [
    "ğŸ•µğŸ» Let's focus on some columns of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303177c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on certain columns\n",
    "columns_of_interest = ['review_id',\n",
    "                       'length_review',\n",
    "                       'review_score',\n",
    "                       'order_id',\n",
    "                       'product_category_name',\n",
    "                       'full_review']\n",
    "df = df[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15afc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50a074",
   "metadata": {},
   "source": [
    "## (2) Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760e250",
   "metadata": {},
   "source": [
    "ğŸ§¹ Create a function `cleaning(sentence)` and apply it to the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1a8987",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cba95e",
   "metadata": {},
   "source": [
    "## (3) Analysis of bad reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a22e9",
   "metadata": {},
   "source": [
    "### (3.1) Dataset with low review scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54315ac",
   "metadata": {},
   "source": [
    "ğŸ˜± What is the proportion of reviews with a rating between 1 and 3 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b872083",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68240840",
   "metadata": {},
   "source": [
    "ğŸ•µğŸ»â€â™‚ï¸ Let's focus on these reviews..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6031ebfc",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a82837",
   "metadata": {},
   "source": [
    "### (3.2) Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79174748",
   "metadata": {},
   "source": [
    "ğŸ”¡ â¡ï¸ ğŸ”¢ Vectorize your texts. \n",
    "\n",
    "* Make sure to take into accounts bigrams.\n",
    "* Set a `max_df` to $0.75$ to remove too frequent words\n",
    "* Spoiler alert: you will end up with $20k+$ words... let's keep only `max_features` = $5000$ for this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6079b9e6",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd051d",
   "metadata": {},
   "source": [
    "### (3.3) LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf10898",
   "metadata": {},
   "source": [
    "ğŸ•µğŸ»â€â™‚ï¸ Fit an LDA:\n",
    "- Choose `n_components = 3`\n",
    "- Show the Document Mixture of Topics  with *.transform()*\n",
    "- Show the Topic Mixture with *.components_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e43be314",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc573a2",
   "metadata": {},
   "source": [
    "#### Document Mixture (of Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2b8e8b2",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16172ca5",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Let's report the most important topic for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c19bb6f",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ca50c",
   "metadata": {},
   "source": [
    "#### Topic Mixture (of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdb0bd3f",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b42e7a",
   "metadata": {},
   "source": [
    "#### Topics\n",
    "\n",
    "ğŸ We provided you with some functions:\n",
    "* `topic_word` returns the top words with their weights for one topic\n",
    "* `print_topics` prints the different topics found by the LDA with their topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9abd69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_word(vectorizer, model, topic, topwords, with_weights = True):\n",
    "    topwords_indexes = topic.argsort()[:-topwords - 1:-1]\n",
    "    if with_weights == True:\n",
    "        topwords = [(vectorizer.get_feature_names_out()[i], round(topic[i],2)) for i in topwords_indexes]\n",
    "    if with_weights == False:\n",
    "        topwords = [vectorizer.get_feature_names_out()[i] for i in topwords_indexes]\n",
    "    return topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f58705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(vectorizer, model, topwords):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"-\"*20)\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print(topic_word(vectorizer, model, topic, topwords))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c4b2f",
   "metadata": {},
   "source": [
    "ğŸ•µğŸ»â€â™‚ï¸ Print the topics with their topwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff15141f",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddda993c",
   "metadata": {},
   "source": [
    "ğŸ‡§ğŸ‡· A bit of Brazilian Portuguese words here:\n",
    "- _cadeiras = chairs_\n",
    "- _producto = product_\n",
    "- _bom = good_\n",
    "- _comprei = bought_\n",
    "- _veio = came_\n",
    "- _duas = two_\n",
    "- _nao = not_\n",
    "- _entregue = delivered_\n",
    "- _pecas = part_\n",
    "- _ainda = yet_\n",
    "- _recebi = received_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de02ddb",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Show the top words associated to a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "add531b3",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c4a4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"most_important_words\"] = df[\"most_important_topic\"].apply(lambda i: topic_word_mixture[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "981a8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"review_id\", \n",
    "        \"review_score\", \n",
    "        \"product_category_name\",\n",
    "        \"full_review_cleaned\",\n",
    "        \"most_important_topic\",\n",
    "        \"most_important_words\"]\n",
    "      ].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905b12b",
   "metadata": {},
   "source": [
    "## (3.4) Pipeline Tf-Idf and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f8a5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998537bc",
   "metadata": {},
   "source": [
    "ğŸ”¨ Create a Pipeline that chains your previous Vectorizer and the LDA.\n",
    "\n",
    "Fit it on the cleaned texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a84df472",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350fd1d",
   "metadata": {},
   "source": [
    "ğŸ’¡ If you try to access the components with `pipeline.components_`, it will NOT work because Pipeline doesn't have a `components_`. However, you can use `pipeline._final_estimator` to access the LDA. And from this, you can access the topics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85a65e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54a2a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline._final_estimator.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eebd9e",
   "metadata": {},
   "source": [
    "**Document Mixture** with the Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be83a10a",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fc08d",
   "metadata": {},
   "source": [
    "**Topic Mixture** with the Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd790708",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ee079",
   "metadata": {},
   "source": [
    "## (4) ğŸ Product Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164fe3fa",
   "metadata": {},
   "source": [
    "### (4.1) Groupby product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa31307",
   "metadata": {},
   "source": [
    "ğŸ“ˆ Group the dataset by `product_category_name` and inspect their performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67cb0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product categories by performance - look at the count, mean, median and std\n",
    "product_categories = df.groupby(by = 'product_category_name').agg({\n",
    "        'review_score': [\"count\", \"mean\", \"median\", \"std\"]\n",
    "    })\n",
    "\n",
    "# Removing products which were sold less than a certain times for the analysis\n",
    "cutoff = 50\n",
    "product_categories = product_categories[product_categories[(\"review_score\", \"count\")] > cutoff]\n",
    "\n",
    "# Sorting the product categories by performance\n",
    "product_categories = product_categories.sort_values(by = [('review_score', 'mean'), \n",
    "                                                          ('review_score', 'std')], \n",
    "                                                    ascending = [False, True])\n",
    "product_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954f1d6",
   "metadata": {},
   "source": [
    "### (4.2) Worst product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b1412",
   "metadata": {},
   "source": [
    "ğŸ‘ Store the five worst categories in terms of *average review score* into a variable called `worst_products`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e511a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_products = product_categories.tail(5).sort_values(by = [(\"review_score\", \"count\")],\n",
    "                                                       ascending = False)\n",
    "worst_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f844ded",
   "metadata": {},
   "source": [
    "ğŸ‘‡ Create a `worst_products_review` DataFrame which contains the `worst_products` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f0b63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_products_reviews = df[df.product_category_name.isin(worst_products.index)]\n",
    "worst_products_reviews[[\"review_id\", \n",
    "                        \"review_score\", \n",
    "                        \"product_category_name\",\n",
    "                        \"full_review_cleaned\",\n",
    "                        \"most_important_topic\",\n",
    "                        \"most_important_words\"]\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37a96e",
   "metadata": {},
   "source": [
    "### (4.3). Topics for the worst products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190cd9a4",
   "metadata": {},
   "source": [
    "â“ What are the topics for the worst products â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fee49a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_products_reviews[\"most_important_topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4daf89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_frequency = list(worst_products_reviews[\"most_important_topic\"].value_counts().index)\n",
    "bad_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "594a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[topic_word_mixture[i] for i in bad_frequency]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f4b7d",
   "metadata": {},
   "source": [
    "## (5) ğŸ Sellers..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa936b",
   "metadata": {},
   "source": [
    "* What kind of products were sold by the worst sellers ?\n",
    "* What are the main reviews for the worst sellers ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95710ae7",
   "metadata": {},
   "source": [
    "### (5.1) Worst Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49794afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers = Seller().get_training_data()\n",
    "sellers.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe8b3e",
   "metadata": {},
   "source": [
    "ğŸ‘‡ Select the 10 worst sellers and store them into a variable called `worst_sellers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6dd1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_sellers = sellers[[\"seller_id\", \"review_score\", \"profits\"]].sort_values(\n",
    "    by = \"profits\", \n",
    "    ascending = True).head(10)\n",
    "worst_sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b881a4",
   "metadata": {},
   "source": [
    "### (5.2) Products sold by the worst sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8adb6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = Product().get_training_data() [[\"product_id\", \"category\"]]\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4750f5",
   "metadata": {},
   "source": [
    "â“ What are the types of products sold by the worst sellers â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3315dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_product_category = data[\"order_items\"].merge(products, \n",
    "                                             on = \"product_id\", how = \"left\")[[\"seller_id\", \"category\"]]\n",
    "\n",
    "sellers_product_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7085c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_product_category.groupby(\"seller_id\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f91192",
   "metadata": {},
   "source": [
    "### (5.3) Categories and topics for the worst sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6687e7e",
   "metadata": {},
   "source": [
    "ğŸ Here are some useful functions:\n",
    "- `focus_seller(seller_id)` to show the product categories sold by a seller\n",
    "- `bad_reviews_seller` to show to topwords of the most frequent topic for one seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a6af560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_seller(seller_id):\n",
    "    return sellers_product_category[sellers_product_category.seller_id == seller_id].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "835bc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews_sellers = df.merge(data[\"order_items\"])\n",
    "bad_reviews_sellers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6a0948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_reviews_seller(bad_reviews_sellers, seller_id):\n",
    "    mask = (bad_reviews_sellers.seller_id == seller_id)\n",
    "    temp = bad_reviews_sellers[mask]\n",
    "    most_frequent_topic_seller = list(temp.most_important_topic.value_counts().head(1).index)[0]\n",
    "    return topic_word_mixture[most_frequent_topic_seller]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b219f6fc",
   "metadata": {},
   "source": [
    "â“For each of these worst sellers, show the most frequent product categories and words â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30722eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for worst_seller in worst_sellers[\"seller_id\"]:\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Focusing on the seller #{worst_seller}...\")\n",
    "    print(focus_seller(worst_seller))\n",
    "    print(bad_reviews_seller(bad_reviews_sellers, worst_seller))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c81d971",
   "metadata": {},
   "source": [
    "ğŸ Congratulations. You've learned some basics of NLP (Preprocessing + Vectorizing + NB/LDA) and we combined this new \"expertise\" with Decision Science\n",
    "\n",
    "ğŸ’¾ Don't forget to `git add / commit / push`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
