{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first embedding\n",
    "\n",
    "## Exercise objectives:\n",
    "- Run your first RNN for NLP\n",
    "- Get a first taste of what an embedding is\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "Words are not something you can easily feed to a Neural Network. For this reason, we have to convert them to something more meaningful. \n",
    "\n",
    "And this is exactly what _Embeddings_ are for! They map any word onto a vectorial representation (this is a fancy way in which  each word corresponds to a vector ;) ). For instance, the word `dog` can be represented by the vector $(w_1, w_2, ..., w_n)$ in the embedding space, and we will learn the weights $(w_k)_k$.\n",
    "\n",
    "So let's just do it.\n",
    "\n",
    "\n",
    "# The data\n",
    "\n",
    "\n",
    "❓ **Question** ❓ Let's first load the data. You don't have to understand what is going on in the function, it does not matter here.\n",
    "\n",
    "⚠️ **Warning** ⚠️ The `load_data` function has a `percentage_of_sentences` argument. Depending on your computer, there are chances that a too large number of sentences will make your compute slow down, or even freeze - your RAM can even overflow. For that reason, **you should start with 10% of the sentences** and see if your computer handles it. Otherwise, rerun with a lower number. \n",
    "\n",
    "⚠️ **DISCLAIMER** ⚠️ **No need to play _who has the biggest_ (RAM) !** The idea is to get to run your models quickly to prototype. Even in real life, it is recommended that you start with a subset of your data to loop and debug quickly. So increase the number only if you are into getting the best accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 21:16:14.819550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-17 21:16:14.819638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/matheus/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937938d7a7374deabc266a8f821ebd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239b9f11760140139a3954838eedef2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/matheus/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:From /home/matheus/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 21:17:47.940907: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-17 21:17:47.940970: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-17 21:17:47.940997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-O26C6N05): /proc/driver/nvidia/version does not exist\n",
      "2022-05-17 21:17:47.943005: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/matheus/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "### Just run this cell to load the data ###\n",
    "###########################################\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "  \n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "    \n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have loaded the data, let's look what is inside !\n",
    "\n",
    "❓ **Question** ❓ You can play with the data here. In particular, `X_train` and `X_test` are lists of sentences. Let's print some of them, with their respective label stored in `y_train` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mann photographs the alberta rocky mountains in a superb fashion and jimmy stewart and walter brennan give enjoyable performances as they always seem to do br br but come on hollywood a mountie telling the people of dawson city yukon to elect themselves a marshal yes a marshal and to enforce the law themselves then gunfighters battling it out on the streets for control of the town br br nothing even remotely resembling that happened on the canadian side of the border during the klondike gold rush mr mann and company appear to have mistaken dawson city for deadwood the canadian north for the american wild west br br canadian viewers be prepared for a reefer madness type of enjoyable howl with this ludicrous plot or to shake your head in disgust',\n",
       " 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(X_train[2]), y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"nathan detroit runs illegal craps games for high rollers in nyc but the heat is on and he can't find a secure location he bets chronic gambler sky masterson that sky can't make a prim missionary sarah brown go out to dinner with him sky takes up the challenge but both men have some surprises in store \\x85 br br this is one of those expensive fifties mgm musicals in splashy colour with big sets loud music larger than life roles and performances to match broadway photographed for the big screen if you like that sort of thing which i don't my main problem with these type of movies is simply the music i like all kinds of music from albinoni to zz top but broadway show tunes in swing time with never ending pah pah tah dah trumpet flourishes at the end of every fourth bar aren't my cup of tea this was written by the tag team of frank loesser mankiewicz jo swerling and abe burrows based on a couple of damon runyon stories and while the plot is quite affable the songs are weak blaine's two numbers for example are identical unnecessary don't advance the plot and grate on the ears and are also flagrantly misogynistic if that sort of thing bothers you there are only two memorable tunes luck be a lady sung by brando not sinatra as you might expect and sit down you're rockin' the boat nicely performed by kaye but you have to sit through two hours to get to them the movie's trump card is a young brando giving a thoughtful laid back performance he also sings quite well and even dances a little and is evenly matched with the always interesting simmons the sequence where the two of them escape to havana for the night is a welcome respite from all the noise bustle and vowel murdering of noo yawk fans of musicals may dig this but in my view a musical has to do something more than just film the stage show\",\n",
       " 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(X_train[19]), y_train[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LABELS**, the task corresponds to a binary classification problem:\n",
    "- label 0 corresponds to a negative movie review\n",
    "- label 1 corresponds to a positive movie review\n",
    "\n",
    "**INPUTS** : The data have been partially cleaned ! So you don't have to worry about it in this exercise. But don't forget this step in real-life challenges. \n",
    "\n",
    "Remember that words are not computer-compatible materials? You have to tokenize them!\n",
    "\n",
    "❓ **Question** ❓ Run the following cell to tokenize your sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# This initializes a Keras utilities that does all the tokenization for you\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# The tokenization learns a dictionnary that maps a token (integer) to each word\n",
    "# It can be done only on the train set - we are not supposed to know the test set !\n",
    "# This tokenization also lower your words, apply some filters, and so on - you can check the doc if you want\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Print some of the tokenized sentences to be sure you got what you expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9033,\n",
       " 7668,\n",
       " 1214,\n",
       " 5563,\n",
       " 18384,\n",
       " 1701,\n",
       " 15,\n",
       " 288,\n",
       " 14898,\n",
       " 8,\n",
       " 4609,\n",
       " 18,\n",
       " 1,\n",
       " 5277,\n",
       " 6,\n",
       " 20,\n",
       " 2,\n",
       " 27,\n",
       " 174,\n",
       " 154,\n",
       " 3,\n",
       " 7669,\n",
       " 2026,\n",
       " 27,\n",
       " 9946,\n",
       " 9947,\n",
       " 11111,\n",
       " 1264,\n",
       " 6653,\n",
       " 12,\n",
       " 1264,\n",
       " 174,\n",
       " 96,\n",
       " 3,\n",
       " 18385,\n",
       " 11112,\n",
       " 2836,\n",
       " 1783,\n",
       " 132,\n",
       " 41,\n",
       " 5,\n",
       " 3095,\n",
       " 16,\n",
       " 88,\n",
       " 1264,\n",
       " 296,\n",
       " 53,\n",
       " 1,\n",
       " 2583,\n",
       " 18,\n",
       " 201,\n",
       " 322,\n",
       " 25,\n",
       " 47,\n",
       " 2429,\n",
       " 8,\n",
       " 996,\n",
       " 3557,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 28,\n",
       " 4,\n",
       " 150,\n",
       " 3694,\n",
       " 5042,\n",
       " 2535,\n",
       " 3096,\n",
       " 8,\n",
       " 18386,\n",
       " 3265,\n",
       " 16,\n",
       " 199,\n",
       " 678,\n",
       " 1415,\n",
       " 211,\n",
       " 2761,\n",
       " 71,\n",
       " 106,\n",
       " 570,\n",
       " 2,\n",
       " 367,\n",
       " 5,\n",
       " 882,\n",
       " 2263,\n",
       " 3558,\n",
       " 15,\n",
       " 1,\n",
       " 199,\n",
       " 273,\n",
       " 42,\n",
       " 23,\n",
       " 35,\n",
       " 12,\n",
       " 430,\n",
       " 4,\n",
       " 145,\n",
       " 60,\n",
       " 10,\n",
       " 90,\n",
       " 54,\n",
       " 294,\n",
       " 420,\n",
       " 16,\n",
       " 131,\n",
       " 509,\n",
       " 4,\n",
       " 98,\n",
       " 6,\n",
       " 345,\n",
       " 1,\n",
       " 211,\n",
       " 10,\n",
       " 35,\n",
       " 29,\n",
       " 3097,\n",
       " 4,\n",
       " 211,\n",
       " 37,\n",
       " 24470,\n",
       " 5,\n",
       " 24471,\n",
       " 328,\n",
       " 18,\n",
       " 2263,\n",
       " 121,\n",
       " 3559,\n",
       " 8,\n",
       " 4109,\n",
       " 55,\n",
       " 16,\n",
       " 116,\n",
       " 265,\n",
       " 14899,\n",
       " 14899,\n",
       " 24472,\n",
       " 14900,\n",
       " 9034,\n",
       " 11113,\n",
       " 30,\n",
       " 1,\n",
       " 125,\n",
       " 4,\n",
       " 159,\n",
       " 2830,\n",
       " 1277,\n",
       " 612,\n",
       " 54,\n",
       " 4426,\n",
       " 4,\n",
       " 3451,\n",
       " 11,\n",
       " 13,\n",
       " 416,\n",
       " 31,\n",
       " 1,\n",
       " 3821,\n",
       " 784,\n",
       " 4,\n",
       " 1115,\n",
       " 24473,\n",
       " 18387,\n",
       " 4807,\n",
       " 24474,\n",
       " 2,\n",
       " 11114,\n",
       " 9035,\n",
       " 407,\n",
       " 20,\n",
       " 3,\n",
       " 372,\n",
       " 4,\n",
       " 4263,\n",
       " 18388,\n",
       " 647,\n",
       " 2,\n",
       " 130,\n",
       " 1,\n",
       " 105,\n",
       " 6,\n",
       " 177,\n",
       " 9948,\n",
       " 1,\n",
       " 740,\n",
       " 24,\n",
       " 889,\n",
       " 24475,\n",
       " 104,\n",
       " 1481,\n",
       " 15,\n",
       " 485,\n",
       " 24,\n",
       " 6263,\n",
       " 1511,\n",
       " 90,\n",
       " 4610,\n",
       " 1,\n",
       " 105,\n",
       " 2,\n",
       " 12722,\n",
       " 20,\n",
       " 1,\n",
       " 4427,\n",
       " 2,\n",
       " 24,\n",
       " 77,\n",
       " 24476,\n",
       " 8266,\n",
       " 42,\n",
       " 12,\n",
       " 430,\n",
       " 4,\n",
       " 145,\n",
       " 8267,\n",
       " 23,\n",
       " 48,\n",
       " 24,\n",
       " 62,\n",
       " 104,\n",
       " 972,\n",
       " 3559,\n",
       " 2184,\n",
       " 26,\n",
       " 3,\n",
       " 686,\n",
       " 5278,\n",
       " 31,\n",
       " 4428,\n",
       " 21,\n",
       " 1847,\n",
       " 14,\n",
       " 23,\n",
       " 226,\n",
       " 567,\n",
       " 2,\n",
       " 848,\n",
       " 182,\n",
       " 330,\n",
       " 14901,\n",
       " 1,\n",
       " 2143,\n",
       " 1963,\n",
       " 3181,\n",
       " 31,\n",
       " 12723,\n",
       " 18,\n",
       " 23,\n",
       " 25,\n",
       " 5,\n",
       " 848,\n",
       " 137,\n",
       " 104,\n",
       " 641,\n",
       " 5,\n",
       " 73,\n",
       " 5,\n",
       " 95,\n",
       " 1,\n",
       " 1412,\n",
       " 12724,\n",
       " 2587,\n",
       " 6,\n",
       " 3,\n",
       " 193,\n",
       " 4428,\n",
       " 759,\n",
       " 3,\n",
       " 3560,\n",
       " 4429,\n",
       " 140,\n",
       " 238,\n",
       " 27,\n",
       " 77,\n",
       " 3555,\n",
       " 177,\n",
       " 70,\n",
       " 2,\n",
       " 58,\n",
       " 3966,\n",
       " 3,\n",
       " 119,\n",
       " 2,\n",
       " 6,\n",
       " 14902,\n",
       " 4611,\n",
       " 16,\n",
       " 1,\n",
       " 206,\n",
       " 219,\n",
       " 8268,\n",
       " 1,\n",
       " 837,\n",
       " 118,\n",
       " 1,\n",
       " 104,\n",
       " 4,\n",
       " 95,\n",
       " 1047,\n",
       " 5,\n",
       " 12725,\n",
       " 15,\n",
       " 1,\n",
       " 281,\n",
       " 6,\n",
       " 3,\n",
       " 1961,\n",
       " 12726,\n",
       " 37,\n",
       " 29,\n",
       " 1,\n",
       " 3822,\n",
       " 18389,\n",
       " 2,\n",
       " 24477,\n",
       " 6654,\n",
       " 4,\n",
       " 24478,\n",
       " 18390,\n",
       " 462,\n",
       " 4,\n",
       " 3096,\n",
       " 186,\n",
       " 3823,\n",
       " 11,\n",
       " 18,\n",
       " 8,\n",
       " 54,\n",
       " 592,\n",
       " 3,\n",
       " 627,\n",
       " 45,\n",
       " 5,\n",
       " 80,\n",
       " 138,\n",
       " 50,\n",
       " 71,\n",
       " 40,\n",
       " 19,\n",
       " 1,\n",
       " 973,\n",
       " 121]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_token[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary that maps each word to a token can be accessed with `tokenizer.word_index`\n",
    "    \n",
    "❓ **Question** ❓ Add a `vocab_size` variable that stores the number of different words (=tokens) in the train set. This is called the _size of the vocabulary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42660"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `X_train_token` and `X_test_token` contain sequences of different lengths.\n",
    "\n",
    "<img src=\"padding.png\" alt='Word2Vec' width=\"700px\" />\n",
    "\n",
    "However, a neural network has to have a tensor as input. For this reason, you have to pad your data.\n",
    "\n",
    "❓ **Question** ❓  Pad your data with the `pad_sequences` function (documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)). Do not forget about the `dtype` and `padding` keywords (but do not use `maxlen` here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RNN\n",
    "\n",
    "Let's now feed this data to a Recurrent Neural Network.\n",
    "\n",
    "❓ **Question** ❓ Write a model that has:\n",
    "- an embedding layer whose `input_dim` is the size of your vocabulary (= your `vocab_size`), and whose `output_dim` is the size of the embedding space you want to have\n",
    "- a RNN (SimpleRNN, LSTM, GRU) layer\n",
    "- a Dense layer\n",
    "- an output layer\n",
    "\n",
    "⚠️ **Warning** ⚠️ Here, you don't need a masking layer. Why? Because `layers.Embedding` has a argument to do that directly, which you have to set with `mask_zero=True`. That also means that your data **HAVE TO** be padded with **0** (which is the default behavior). See the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding#example_2) to understand how it **impacts** the `input_dim`.\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Hint</summary>\n",
    "\n",
    "`input_dim` should equal size of vocabulary + 1\n",
    "\n",
    "</details>\n",
    "\n",
    "Compile it with the appropriate arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Embedding(input_dim=vocab_size+1, output_dim=50, mask_zero=True))\n",
    "model.add(layers.LSTM(20))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Look at the number of parameters in your RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          2133050   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20)                5680      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                210       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,138,951\n",
      "Trainable params: 2,138,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Check that the number of parameters in your embedding layer is equal to the number of words in your vocabulary, times the dimension of your embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Start fitting your model with 20 epochs, with an early stopping criterion whose patience is equal to 4.\n",
    "\n",
    "⚠️ **Warning** ⚠️ You might see that it takes a lof ot time! \n",
    "\n",
    "**So stop it after a couple of iterations!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 20/110 [====>.........................] - ETA: 4:13 - loss: 0.6925 - accuracy: 0.4938"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_586/2552568411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train, epochs=20, validation_split=0.3, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not waste too much time just staring at our screen or taking coffees. It is too early to start having breaks ;)\n",
    "\n",
    "❓ **Question** ❓ We will reduce the computational time. To start, let's first look at how many words there are in the different sentences of your train set (Just run the following cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_hist(X):\n",
    "    len_ = [len(_) for _ in X]\n",
    "    plt.hist(len_)\n",
    "    plt.title('Histogram of the number of sentences that have a given number of words')\n",
    "    plt.show()\n",
    "    \n",
    "plot_hist(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably see that 90 to 95% of your sentences have less than 300 words. And very few have more than 1000.\n",
    "\n",
    "However, as you didn't use `maxlen` in your padding above, your input tensor has a dimension equal to the length of the sentence that has the maximum number of words.\n",
    "\n",
    "Now, let's look at how it affects the padding : \n",
    "\n",
    "\n",
    "<img src=\"tensor_size.png\" alt='Word2Vec' width=\"700px\" />\n",
    "\n",
    "Because of a very few number of sentences, one dimension of your tensor is equal to something like 1000. And most of the sentences that have 200 words have just padded values that are useless.\n",
    "\n",
    "So your tensor is mostly useless information. But which still takes time to train.\n",
    "\n",
    "But what if you pad the data to a maximum length (`maxlen`) of say 200 (words)?\n",
    "- First, that would increase the convergence and you would not need to stare at your screen while waiting for the algorithm to converge\n",
    "- But in essence, do you really lose that much information? Do you think that you often need more than 200 words (up to 1000) to tell wheter or not a sentence is positive of negative?\n",
    "\n",
    "❓ **Question** ❓ For all these reasons, come back to your padding and use the `maxlen` keywords and rerun the model !  See how faster it goes now - without hurting the performances ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad2 = pad_sequences(X_train_token, maxlen=200, dtype='float32', padding='post')\n",
    "X_test_pad2 = pad_sequences(X_test_token, maxlen=200, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(layers.Embedding(input_dim=vocab_size+1, output_dim=50, mask_zero=True))\n",
    "model2.add(layers.LSTM(20))\n",
    "model2.add(layers.Dense(10, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 20s 273ms/step - loss: 0.6596 - accuracy: 0.6271 - val_loss: 0.7204 - val_accuracy: 0.6553\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.4198 - accuracy: 0.8426 - val_loss: 0.4162 - val_accuracy: 0.8287\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 13s 243ms/step - loss: 0.2175 - accuracy: 0.9300 - val_loss: 0.3702 - val_accuracy: 0.8373\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 14s 247ms/step - loss: 0.1205 - accuracy: 0.9629 - val_loss: 0.4266 - val_accuracy: 0.8340\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 14s 252ms/step - loss: 0.0559 - accuracy: 0.9851 - val_loss: 0.5078 - val_accuracy: 0.8320\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 14s 246ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.5594 - val_accuracy: 0.8353\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.6583 - val_accuracy: 0.8313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e10560220>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train_pad2, y_train, epochs=20, validation_split=0.3, batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 7s 44ms/step - loss: 0.3571 - accuracy: 0.8476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35711637139320374, 0.847599983215332]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_pad2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
